# Class 2 Week 3

[TOC]

# 前言

![image-20221127145121736](assets/image-20221127145121736.png)

**fruitful**-卓有成效的

![image-20221127145201143](assets/image-20221127145201143.png)

**diagnostics**-诊断学 

# 模型评估-ebaluating model

## 应用到线性回归

![image-20221127145453175](assets/image-20221127145453175.png)

如果只是绘制，那么4维数据就画不出来了；划分训练集，一部分训练，一部分检验。

![image-20221127145706933](assets/image-20221127145706933.png)

$ J_{test}$ 衡量模型在测试集上的性能。
$J_{train}$ 衡量模型在训练集上的性能。

![image-20221127150016450](assets/image-20221127150016450.png)

![image-20221127150045873](assets/image-20221127150045873.png)

## 应用到分类问题


对于分类问题：
除了和回归问题类似的计算方法，还有另一种方法。

计算在训练集或者测试集上分类错误的比例。

被错误分类了，就记为1，所以J的数值代表了分类错误的数据个数。

![image-20221127150205492](assets/image-20221127150205492.png)

![image-20221127150336692](assets/image-20221127150336692.png)

# 模型选择与交叉验证

## 选择方法与交叉验证

一旦模型参数 *w* 和 b 已经适合训练集，$ J_{train}$ 要比实际的泛化误差（不在训练集中的新示例的平均误差）要低，而$ J_{test}$ 能较好地（相对于 $ J_{train}$）估计泛化误差。

![image-20221127150532421](assets/image-20221127150532421.png)

![image-20221127150915807](assets/image-20221127150915807.png)

直观上，我们在选择模型的时候会选择一个$ J_{test}$ 最小的模型，当我们想估计这个模型表现如何时，可以直接报告$ J_{test}$ 。
但这个过程有一个缺陷就是 Jtest 很可能是泛化误差的乐观估计（低于实际的泛化误差）。
可以类比到使用训练集训练 w 和 b 会使$ J_{train}$ 成为泛化误差的一个过度乐观估计，使用测试集训练 d(多项式次数) 也会使 $ J_{test}$ 成为泛化误差的乐观估计。
PS：我自己的理解，使用训练集我们想选择的就是适当的 w 和 b 使得$ J_{train}$ 最小，对于未知数据集来讲，这是一个最乐观的估计，使用测试集选择模型时，我们选择的也是合适的 d 使得$ J_{test}$ 最小，此时再用 $ J_{test}$  作为泛化误差，肯定也是偏小的。

![image-20221127151108310](assets/image-20221127151108310.png)

![image-20221127151236355](assets/image-20221127151236355.png)

所以，我们将数据集分为**训练集**、**交叉验证集**、**测试集**。
交叉验证集用于检查不同模型的有效性和真实性，也叫做验证集、开发集。

所以我们**选择合适模型**的方法是：使用训练集拟合参数，使用交叉验证集选择模型，使用测试集估计泛化误差。

![image-20221127151845390](assets/image-20221127151845390.png)

![image-20221127151904437](assets/image-20221127151904437.png)

[本初ben](https://www.zhihu.com/question/265443164/answer/2417856431)

- **训练集**

**参与训练**，模型从训练集中学习经验，从而不断减小训练误差。这个最容易理解，一般没什么疑惑。

- **验证集**

**不参与训练**，用于在训练过程中检验模型的状态，收敛情况。验证集通常用于调整超参数，根据几组模型验证集上的表现决定哪组超参数拥有最好的性能。

同时验证集在训练过程中还可以用来监控模型是否发生过拟合，一般来说验证集表现稳定后，若继续训练，训练集表现还会继续上升，但是验证集会出现不升反降的情况，这样一般就发生了[过拟合](https://www.zhihu.com/search?q=过拟合&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2417856431})。所以验证集也用来判断何时停止训练。

- **测试集**

**不参与训练**，用于在训练结束后对模型进行测试，评估其[泛化能力](https://www.zhihu.com/search?q=泛化能力&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2417856431})。在之前模型使用**验证集**确定了**超参数**，使用**训练集**调整了**可训练参数**，最后使用一个从没有见过的数据集来判断这个模型的好坏。 **需要十分注意的是：测试集仅用于最终评价模型的好坏，在测试集上得到的指标可以用来和别人训练的模型做对比，或者用来向别人报告你的模型效果如何。切记千万不能根据模型在测试集上的指标调整模型超参数（这是验证集应该干的事情），这会导致模型对测试集过拟合，使得[测试集](https://www.zhihu.com/search?q=测试集&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2417856431})失去其测试效果的客观性和准确性。**

# 模型参数选择

## 诊断方差偏差

从这里就只考虑train跟cv两个数据集了，text数据集只是用来做展示（输出）用的，不参与状态检验，只是用来评估

单个变量比较直观，**bias**-偏差，**variance**-方差

![image-20221127155244945](assets/image-20221127155244945.png)

可以画出不同模型下的偏差与方差的图像

随着多项式次数的增加，显示发生欠拟合、然后是恰好拟合、最后发生过拟合，$J_{train}$ 越来越低，$J_{cv}$先降低后升高。

![image-20221127155802244](assets/image-20221127155802244.png)



![image-20221127160232682](assets/image-20221127160232682.png)

综上，诊断学习算法的偏差和方差的方法：

- 如果 $J_{train}$很高，则具有高偏差。
- 如果  $J_{cv}$远高于 $J_{train}$，则具有高方差。
- 如果 $J_{train}$很高，并且   $J_{cv}$远高于 $J_{train}$，则同时具有高偏差和高方差。
- 对于部分数据发生过拟合，对于部分数据发生欠拟合时，会出现同时具有高偏差和高方差的情况

## 正则化参数

λ 很大时，代价函数会过于注重减小参数的值，极端情况参数为 0，发生欠拟合；
λ 很小时，代价函数会过于注重拟合数据，极端情况 λ 为 0，发生过拟合。

![image-20221127161043605](assets/image-20221127161043605.png)

![image-20221127161326504](assets/image-20221127161326504.png)

![image-20221127161847576](assets/image-20221127161847576.png)

看着是对称的（方差看Jcv，偏差看Jtrain）

- ==左侧==的**左边**是$\lambda$比较小，过拟合，方差大，偏差小，**右边**是$\lambda$比较大，欠拟合，方差大，偏差大

- ==右侧==是**左边**次数低，欠拟合，方差大，偏差大，**右边**是次数高，过拟合，方差大，偏差小

# 误差的分析

## 搭建性能-Baseline（基线）

例子：语音识别:

<img src="assets/image-20221127164044984.png" alt="image-20221127164044984" style="zoom:67%;" />

$J_{train}$ = 10.8% 意味着训练集中有 89.2% 的音频被正确识别。
直观上看来，训练集误差和交叉验证集误差都很高，但事实上我们还有另一项有用的标准，人类表现性能，即人类识别的正确率，训练误差仅比人类识别误差高 0.2%，而交叉验证误差比训练误差高 4.0%，因此可以看出此模型具有高方差问题而不是高偏差问题。

![image-20221127164113562](assets/image-20221127164113562.png)

当判断训练误差是否高时，通常建立一个性能评估基准。


![image-20221127170034648](assets/image-20221127170034648.png)

前两个数据之间的差距决定了是否存在高偏差问题，后两个数据之间的差距决定了是否存在高方差问题。

## 学习曲线-Learning curves

三个点确定一个二次方程（三个未知数）

![image-20221127170509317](assets/image-20221127170509317.png)

- **high-bias**

![image-20221127170814514](assets/image-20221127170814514.png)

> 因为是$J_{train}$跟$J_{cv}$取得平均值，所以不会取余无穷（无穷的1取平均最后也是1），而且大于最小值，小于最大值（最大值与最小值有限）故这个平均值有界

- **high-variance**

误差低到不切实际

![image-20221127171547474](assets/image-20221127171547474.png)

实际上最好的情况是三者相等，模型最接近人类（一味的扩大训练集，花费很很高）

## 误差与方差的分析（下一步该改进什么）

![image-20221127172506550](assets/image-20221127172506550.png)

- 扩大训练集-让拟合想过更好，更符合现实，对于high bias问题作用不大，但是能使得high variance更加拟合
- 减少特征向量-模型不会过于复杂（不会过拟合）对于high variance更小，但是对于high bias甚至可能从过拟合变成欠拟合
- 增加特征向量-模型变复杂，像过拟合过度所以对high bias有效，high variance作用小
- 增加次数项-相当于增加特征向量
- 减小$\lambda$-w的占比更小，自由发挥，趋向于过拟合，治疗high bias的问题
- 增大$\lambda$-w的占比变大，会压制w，趋向于欠拟合，治疗high variance的问题

> 主要是看趋向于欠拟合还是过拟合，==欠拟合（high bias）==，==过拟合（high variance）==

- **high variance**：1，增加训练集；2，简化模型：减少特征向量or增大$\lambda$；这样就很难拟合复杂曲线。
- **high bias**：复杂模型：增加特征向量or减小$\lambda$

# 神经网络与误差偏差

**tradeoff**-权衡

![image-20221127202013714](assets/image-20221127202013714.png)

首先进行模型扩张，起码要比人强

![image-20221127202553694](assets/image-20221127202553694.png)

> 误差大了就扩大网络，方差大了就增多数据

只要正则化选择的正确，就不会出现过拟合导致方差增大，==大的网络往往更好==

![image-20221127202808229](assets/image-20221127202808229.png)

![image-20221127203006737](assets/image-20221127203006737.png)

**非正则化**与**正则化**的模型

# 机器学习的迭代循环

![image-20221127203617102](assets/image-20221127203617102.png)

![image-20221127203916623](assets/image-20221127203916623.png)

![image-20221127204011502](assets/image-20221127204011502.png)

蜜罐计划-**Honeypot**

蜜罐的定义（from 百度）

首先我们要弄清楚一台蜜罐和一台没有任何防范措施的计算机的区别，虽然这两者都有可能被入侵破坏，但是本质却完全不同，蜜罐是网络管理员经过周密布置而设下的“黑匣子”，看似漏洞百出却尽在掌握之中，它收集的入侵数据十分有价值；而后者，根本就是送给入侵者的礼物，即使被入侵也不一定查得到痕迹……因此，蜜罐的定义是：“蜜罐是一个安全资源，它的价值在于被探测、攻击和损害。”

设计蜜罐的初衷就是让黑客入侵，借此收集证据，同时隐藏真实的服务器地址，因此我们要求一台合格的蜜罐拥有这些功能：发现攻击、产生警告、强大的记录能力、欺骗、协助调查。另外一个功能由管理员去完成，那就是在必要时候根据蜜罐收集的证据来起诉入侵者。

# 如何高效的改进模型

## 误差分析-error analysis

有的很多错误分类的数据，自己看一遍然后分析其中的问题所在

![image-20221127204723210](assets/image-20221127204723210.png)

指出模型实际上应该朝着什么方向发展才更好（再怎么优化恶意拼写，也只能解决3%的问题）

**pharma**-药品

![image-20221127205036489](assets/image-20221127205036489.png)

![image-20221127205131497](assets/image-20221127205131497.png)

![image-20221127205141994](assets/image-20221127205141994.png)

**error analysis**的重要性

## 数据添加-adding data

>  专项的添加需要的数据，比一味的添加各种数据更加有效，怎么寻找方法来改进代码

**数据增强**-Data augmentation：用已有的例子去构造新例子

![image-20221127205756711](assets/image-20221127205756711.png)

![image-20221127205814128](assets/image-20221127205814128.png)

构造丰富的数据库，让机器学习的更加稳健

![image-20221127205900240](assets/image-20221127205900240.png)

音频的叠加与加噪，用来训练

![image-20221127210106763](assets/image-20221127210106763.png)

![image-20221127210138017](assets/image-20221127210138017.png)

有一些处理，比如说噪点之类的，平时生活中遇不到，所以就不做这些处理

**OCR**算法

![image-20221127210304529](../../../Jupyter Projects/2022-Machine-Learning/assets/image-20221127210304529.png)

![image-20221127210410268](assets/image-20221127210410268.png)

右侧是自己做的数据集，说明完全可以自己去生成数据集以减少处理数据花费的时间

![image-20221127210623750](assets/image-20221127210623750.png)

有的专注于改进代码，有的算法已经够好了，就要在数据上下功夫

## 迁移学习-transfer learing

> 把其他的数据用到自己的身上（但是要相近，比如识别猫的用来识别狗）就像兽医给人看病

option1适合小的网络，opinton适合所有的(小的用1比较好)，**Fine tuning**-微调

![image-20221129200441728](assets/image-20221129200441728.png)

就像识别人之前，可以先训练去学习识别其他东西（这里相同的类型指不要用图像识别去识别语音）

![image-20221129200807554](assets/image-20221129200807554.png)

微调就可以用少量的数据集去训练

![image-20221129201001367](assets/image-20221129201001367.png)

主要是大家可以用来互相交流，用那些训练过的大型网络

# 构造系统的全流程

![image-20221129201426113](assets/image-20221129201426113.png)

- 确定计划
- 收集数据
- 模型训练（再看看还要什么数据）
- 发布（维护，更新）

**inference server**-推断服务器，**monitoring**-监控系统（统计什么时候训练不好以方便观察改进）

![image-20221129202243775](assets/image-20221129202243775.png)

**opera**-维护，运作

# 公平，偏见，伦理-fairness，bias，ethics

![image-20221129202453387](assets/image-20221129202453387.png)

![image-20221129202538516](assets/image-20221129202538516.png)

![image-20221129202643683](assets/image-20221129202643683.png)

要对社会有积极影响，不要为了钱而损害社会

**diverse**-多元化（种族，性别，信仰等等，这里指团体的）

**audit**-检查，审计，大学生旁听

![image-20221129203131793](assets/image-20221129203131793.png)

# 选修-数据倾斜与优化方法

## 数据倾斜介绍

数据并非55开，错误数据很少时

![image-20221129203430066](assets/image-20221129203430066.png)

如果是一个很罕见的症状，正确率99.5%或者说错误率0.5%，也说明误差最小的不一定是最准的

**precision**-精确率（你识别的这些阳性，有多少是真阳的），**recall**-召回率（所有的阳性里，真正识别出来的是多少）

![image-20221129204239021](assets/image-20221129204239021.png)

如果只是print（y=0)那么矩阵是[0 0;1 99],此处假设100个人里1个阳性，那么precision是0/0（无定义or不存在精度），recall是0

## 权衡精度与召回率

高精准率意味着如果诊断出患有这种罕见疾病的患者，很可能就患病，即这是一个准确的诊断。
高召回率意味着如果有一个还有这种罕见病的患者，算法很可能会正确识别出他们确实患有这种病。
那么如何在精准率和召回率之间权衡呢？

![image-20221129205957561](assets/image-20221129205957561.png)

当提高阈值时，准确率提高，召回率降低；降低阈值时，准确率降低，召回率提高。
根据不同的阈值我们可以画出精准率和召回率曲线。
除了手动选择阈值以外，我们话可以定义一个指标，**F1 分数***。

F1 分数是一种计算平均分数的方法，它更关注较低的分数，也叫调和均值。

![image-20221129210605883](./assets/image-20221129210605883.png)
