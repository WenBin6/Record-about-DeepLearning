本周学习了Machine learning第二课第二周的内容，并简单使用了tensorflow提供的API模拟了神经网络的训练过程。

##### 神经网络模型训练细节：

神经网络的训练步骤与逻辑回归模型类似，可分为三个步骤：

1.建立神经网络模型计算输出结果

2.定义成本函数

3.使用反向传播算法减少误差



##### 神经网络主流的三种激活函数：

- 二元分类问题-**Sigmoid**
- 回归问题-**Linear activation functions**线性激活函数
- 非负回归问题-**ReLU**

![image-20221127100640505](assets/image-20221127100640505-1685888058443-3.png)



##### 多分类问题

在实际应用情景中，物品属于多个类别，只有0/1两种预测值的逻辑回归模型不足以将物品区分为多个类别。

于是我们使用softmax模型来解决多分类问题：

**embelish**-美化（泛化，推广）

![image-20221127103035206](assets/image-20221127103035206.png)

我们在输出层使用softmax模型，可以得到输入的$X$属于数字0-9的概率。

特有属性，比喻要把所有的z计算出来才可以算a。

![image-20221127113627875](assets/image-20221127113627875.png)
